Research papers

Paper
"Inference-Time Scaling for Generalist Reward Modeling (DeepSeek, April 2025, 42 pages)

Paper: https://arxiv.org/abs/2504.02495v1 "
"Sample, Don't Search: Rethinking Test-Time Alignment for Language Models

Gonçalo Faria, Noah A. Smith: https://arxiv.org/abs/2504.03790"
"Agentic Knowledgeable Self-awareness (Zhejiang University, April 2025)

Paper: https://arxiv.org/abs/2504.03553 "
"RARE: Retrieval-Augmented Reasoning Modeling (Peking University, March 2025)

Paper: https://arxiv.org/abs/2503.23513 "
"Sample, Scrutinize and Scale: Effective Inference-Time Search by Scaling Verification (Google Research, February 2025, 48 pages)

Paper: https://arxiv.org/abs/2502.01839 "
"FFN Fusion: Rethinking Sequential Computation in Large Language Models
paper: chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://arxiv.org/pdf/2503.18908"
"Can Memory-Augmented Language Models Generalize on Reasoning-in-a-Haystack Tasks? (IBM Research, March 2025)

Paper: https://arxiv.org/abs/2503.07903v1 "
"What Makes a Reward Model a Good Teacher? An Optimization Perspective

https://arxiv.org/abs/2503.15477"
"A Review of DeepSeek Models' Key Innovative Techniques (University of Texas at Dallas, March 2025)

Paper: https://arxiv.org/abs/2503.11486 "
"L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning (Carnegie-Mellon University, March 2025)

Paper: https://arxiv.org/abs/2503.04697 "
"Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers (University of Waterloo, March 2025)

Paper: [https://arxiv.org/abs/2503.11579](https://arxiv.org/abs/2503.11579) "
"What I cannot execute, I do not understand: Training and Evaluating LLMs on Program Execution Traces
Meta AI 2025
https://arxiv.org/abs/2503.05703"
"Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching (KAIST, March 2025)

Paper: https://arxiv.org/abs/2503.05179 "
"START: Self-taught Reasoner with Tools (Alibaba Group, March 2025)

Paper: https://arxiv.org/abs/2503.04625 "
"LADDER: Self-Improving LLMs Through Recursive Problem Decomposition (Tufa Labs, March 2025)

Paper: https://arxiv.org/abs/2503.00735 "
"LLM Post-Training: A Deep Dive into Reasoning Large Language Models (Mohamed bin Zayed University, February 2025)

Paper: [https://arxiv.org/abs/2502.21321](https://arxiv.org/abs/2502.21321) "
"LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET
https://arxiv.org/abs/2310.01798"
"Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning? (Alibaba Group, February 2025)

Paper: [https://arxiv.org/abs/2502.19361](https://arxiv.org/abs/2502.19361)"
"Large Language Diffusion Models (Renmin University of China, February 2025)

Paper: [https://arxiv.org/abs/2502.09992](https://arxiv.org/abs/2502.09992) "
"Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models (Tsinghua University, January 2025)

Paper: [https://arxiv.org/abs/2501.09686](https://arxiv.org/abs/2501.09686) "
"Kimi k1.5: Scaling Reinforcement Learning with LLMs (MoonshotAI, January 2025)

Paper: [https://arxiv.org/abs/2501.12599v1]"
"Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning
https://arxiv.org/abs/2501.12948"
"Towards reasoning era: A survey of long chain-of-thought for reasoning large language models
https://arxiv.org/abs/2503.09567"
"Large Language Model based Multi-Agents: A Survey of Progress and Challenges
https://arxiv.org/abs/2402.01680"
"Large Concept Models: Language Modeling in a Sentence Representation Space
https://arxiv.org/abs/2412.08821"
"The Future of AI: Exploring the Potential of Large Concept Models
https://arxiv.org/abs/2501.05487"
"LLMS STILL CAN’T PLAN; CAN LRMS? A PRELIMINARY EVALUATION OF OPENAI’S O1 ON PLANBENCH
https://arxiv.org/abs/2409.13373"
"Enhancing reasoning capabilities of llms via principled synthetic logic corpus
https://proceedings.neurips.cc/paper_files/paper/2024/hash/8678da90126aa58326b2fc0254b33a8c-Abstract-Conference.html"
"ContrastScore: Towards Higher Quality, Less Biased, More Efficient Evaluation Metrics with Contrastive Evaluation
https://arxiv.org/abs/2504.02106"
"RepEval: Effective Text Evaluation with LLM Representation
https://arxiv.org/abs/2404.19563"
"AXCEL: Automated eXplainable consistency evaluation using LLMs
https://arxiv.org/abs/2409.16984"
"ICE-Score: Instructing Large Language Models to Evaluate Code
https://arxiv.org/abs/2304.14317"
"Uncertainty aware learning for language model alignment
https://arxiv.org/abs/2406.04854"
"CURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning
https://arxiv.org/abs/2503.13517"
"Coannotating: Uncertainty-guided work allocation between human and large language models for data annotation
https://arxiv.org/abs/2310.15638"
"Empowering Large Language Models for Textual Data Augmentation
https://arxiv.org/abs/2404.17642"
"Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks
https://arxiv.org/abs/2402.13482"
"Mamba: Linear-time sequence modeling with selective state spaces
chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://minjiazhang.github.io/courses/fall24-resource/Mamba.pdf"
"The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search
https://pub.sakana.ai/ai-scientist-v2/paper/paper.pdf"
"Exploring Expert Failures Improves LLM Agent Tuning

Li-Cheng Lan, Andrew Bai, Minhao Cheng, Ruochen Wang, Cho-Jui Hsieh, Tianyi Zhou

UCLA, Penn State University, OpenAI, University of Maryland
2025
https://arxiv.org/abs/2504.13145"
"A Survey on Knowledge Distillation of Large Language Models
https://arxiv.org/abs/2402.13116"
"Judging llm-as-a-judge with mt-bench and chatbot arena
https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html"



























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































